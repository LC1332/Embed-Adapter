{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMeMJtt98MbhwiS3FdnnHVW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/Embed-Adapter/blob/main/notebook/Embed_Adapter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "我打算先建立一个 openAI(预先存储), 和bge-medium和bge-small之间相互转化的代码\n",
        "\n",
        "- [x] 从google drive进行数据读取\n",
        "- [x] 进行batch循环，调通基础的batch embedding抽取\n",
        "- [x] 判断哪些模型之间的数据是需要被记录的，记录x'x和x'y\n",
        "- [ ] 计算伪逆并进行初步的存储\n"
      ],
      "metadata": {
        "id": "A5EQAQXl3_m0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnGJL7ih3-cp",
        "outputId": "d80b6828-2e0d-4a7c-cde6-dfc4c279ace8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/unpublic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRBwpYv95iqO",
        "outputId": "978e519f-24d0-4b79-c9f2-17531ebaef25"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatHaruhi_Waifu_extended.jsonl  erotics.jsonl\tzhwiki_2k_embedding.jsonl  星绘.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "这段代码是特别处理之前我们在训练LuotuoBert的时候使用的left-right格式的代码"
      ],
      "metadata": {
        "id": "fH3ayZtx6BmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "下载链接\n",
        "\n",
        "https://drive.google.com/file/d/1JLJ68Xs67ZihZnygohwDtJ2uKEIEuuu1/view?usp=sharing"
      ],
      "metadata": {
        "id": "5jJqoDU7Ni8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fname = \"/content/drive/MyDrive/unpublic/zhwiki_2k_embedding.jsonl\"\n",
        "\n",
        "import json\n",
        "\n",
        "raw_datas = []\n",
        "\n",
        "with open(fname, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        if line.strip() == \"\":\n",
        "            continue\n",
        "        data = json.loads(line)\n",
        "        raw_datas.append(data)\n",
        "\n",
        "raw_datas = raw_datas[:100]"
      ],
      "metadata": {
        "id": "KN1829gH52ey"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(raw_datas[0].keys())\n",
        "print(raw_datas[0])"
      ],
      "metadata": {
        "id": "upI__c1e5_8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datas = []\n",
        "for data in raw_datas:\n",
        "    datas.append({\n",
        "        \"text\": data[\"left\"],\n",
        "        \"embedding\": data[\"left_embedding\"],\n",
        "    })\n",
        "    datas.append({\n",
        "        \"text\": data[\"right\"],\n",
        "        \"embedding\": data[\"right_embedding\"],\n",
        "    })"
      ],
      "metadata": {
        "id": "9f1kpb826Gov"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(datas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU9ZsAr3-vnw",
        "outputId": "e21d29a4-7625-4d3d-a003-86e93ac9b25e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "把bge家族的代码放过来\n",
        "\n",
        "TODO: 把这个代码移动到repo里"
      ],
      "metadata": {
        "id": "1ZUB969X6jaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "_model_pool = {}\n",
        "_tokenizer_pool = {}\n",
        "\n",
        "# BAAI/bge-small-zh-v1.5\n",
        "\n",
        "def get_general_embeddings( sentences , model_name = \"BAAI/bge-small-zh-v1.5\" , return_tensor = False):\n",
        "\n",
        "    global _model_pool\n",
        "    global _tokenizer_pool\n",
        "\n",
        "    if model_name not in _model_pool:\n",
        "        from transformers import AutoTokenizer, AutoModel\n",
        "        _tokenizer_pool[model_name] = AutoTokenizer.from_pretrained(model_name)\n",
        "        _model_pool[model_name] = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "    _model_pool[model_name].eval()\n",
        "\n",
        "    # Tokenize sentences\n",
        "    encoded_input = _tokenizer_pool[model_name](sentences, padding=True, truncation=True, return_tensors='pt', max_length = 512)\n",
        "\n",
        "    # Compute token embeddings\n",
        "    with torch.no_grad():\n",
        "        model_output = _model_pool[model_name](**encoded_input)\n",
        "        # Perform pooling. In this case, cls pooling.\n",
        "        sentence_embeddings = model_output[0][:, 0]\n",
        "\n",
        "    # normalize embeddings\n",
        "    sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
        "    if return_tensor == True:\n",
        "        return sentence_embeddings\n",
        "    return sentence_embeddings.cpu().tolist()\n",
        "\n",
        "def get_general_embedding( text_or_texts , model_name = \"BAAI/bge-small-zh-v1.5\" ):\n",
        "    if isinstance(text_or_texts, str):\n",
        "        return get_general_embeddings([text_or_texts], model_name)[0]\n",
        "    else:\n",
        "        return get_general_embeddings_safe(text_or_texts, model_name)\n",
        "\n",
        "general_batch_size = 16\n",
        "\n",
        "import math\n",
        "\n",
        "def get_general_embeddings_safe(sentences, model_name = \"BAAI/bge-small-zh-v1.5\"):\n",
        "\n",
        "    embeddings = []\n",
        "\n",
        "    num_batches = math.ceil(len(sentences) / general_batch_size)\n",
        "\n",
        "    for i in tqdm( range(num_batches) ):\n",
        "        # print(\"run bge with batch \", i)\n",
        "        start_index = i * general_batch_size\n",
        "        end_index = min(len(sentences), start_index + general_batch_size)\n",
        "        batch = sentences[start_index:end_index]\n",
        "        embs = get_general_embeddings(batch, model_name)\n",
        "        embeddings.extend(embs)\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "def get_bge_zh_embedding( text_or_texts ):\n",
        "    return get_general_embedding(text_or_texts, \"BAAI/bge-small-zh-v1.5\")"
      ],
      "metadata": {
        "id": "_v0aLVPO6fC7"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "对embedding函数的测试\n",
        "\n",
        "测试这两个\n",
        "\n",
        "BAAI/bge-small-zh-v1.5\n",
        "\n",
        "BAAI/bge-base-zh-v1.5"
      ],
      "metadata": {
        "id": "N5f7mS4s7dO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test_batch_n = 4\n",
        "\n",
        "# test_batch = [data[\"text\"] for data in datas[:test_batch_n]]\n",
        "\n",
        "# bge_small_15 = get_general_embeddings(test_batch, \"BAAI/bge-small-zh-v1.5\", return_tensor = True)\n",
        "\n",
        "# bge_base_15 = get_general_embeddings(test_batch, \"BAAI/bge-base-zh-v1.5\", return_tensor = True)"
      ],
      "metadata": {
        "id": "4bUHrp4z6f6m"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "X_1 = bge_small_15 是一个 4 * 512的tensor\n",
        "\n",
        "X_2 = bge_base_15 是一个 4 * 768的tensor\n",
        "\n",
        "我想 1. 验证X_i 是否每行都被l_2归一化\n",
        "\n",
        "2. 计算X_i^T X_i，以及X_1^T X_2的值，\n",
        "\n",
        "请用python为我实现"
      ],
      "metadata": {
        "id": "vp_2UBud9lch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们现在开始来正规写程序"
      ],
      "metadata": {
        "id": "NV_3Tqwr-i7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [data[\"text\"] for data in datas]\n",
        "openai_embeddings = [data[\"embedding\"] for data in datas]"
      ],
      "metadata": {
        "id": "68ylfCmY-Mk8"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_config = {\n",
        "    \"name\":\"openai\",\n",
        "    \"embeddings\":openai_embeddings, # 预先抽取的\n",
        "    \"batch_embed_fun\":None\n",
        "}\n",
        "\n",
        "def bge_small_zh_fun( texts ):\n",
        "    return get_general_embeddings(texts, \"BAAI/bge-small-zh-v1.5\", return_tensor = True)\n",
        "\n",
        "bge_small_config = {\n",
        "    \"name\":\"bge_small_zh_15\",\n",
        "    \"embeddings\":None,\n",
        "    \"batch_embed_fun\":bge_small_zh_fun\n",
        "}\n",
        "\n",
        "def bge_base_zh_fun( texts ):\n",
        "    return get_general_embeddings(texts, \"BAAI/bge-base-zh-v1.5\", return_tensor = True)\n",
        "\n",
        "bge_base_config = {\n",
        "    \"name\":\"bge_base_zh_15\",\n",
        "    \"embeddings\":None,\n",
        "    \"batch_embed_fun\":bge_base_zh_fun\n",
        "}\n",
        "\n",
        "method_configs = [openai_config, bge_small_config, bge_base_config]\n",
        "\n",
        "forbidden_pairs = [] # 如果你某个pair不希望生成，需要把 model_A_2_model_B 放到这个list里面"
      ],
      "metadata": {
        "id": "edGpTmbm-3OD"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(texts)\n",
        "\n",
        "n_method = len(method_configs)\n",
        "batch_size = 8\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "corr_map = {}\n",
        "\n",
        "for start_id in tqdm(range(0,n, batch_size)):\n",
        "    end_id = min(start_id + batch_size, n)\n",
        "    texts_batch = texts[start_id:end_id]\n",
        "\n",
        "    method2embeddings = {}\n",
        "\n",
        "\n",
        "    for method_config in method_configs:\n",
        "        method_name = method_config[\"name\"]\n",
        "        if method_config[\"embeddings\"] is None:\n",
        "            embeddings = method_config[\"batch_embed_fun\"](texts_batch)\n",
        "        else:\n",
        "            embeddings = torch.tensor(method_config[\"embeddings\"][start_id:end_id]).cpu()\n",
        "\n",
        "        if embeddings.device != torch.device(\"cpu\"):\n",
        "            embeddings = embeddings.cpu()\n",
        "\n",
        "        method2embeddings[method_name] = embeddings\n",
        "\n",
        "    for method_i in range(n_method):\n",
        "        for method_j in range(method_i, n_method):\n",
        "            corr_index = ( method_i, method_j )\n",
        "            X_1 = method2embeddings[method_configs[method_i][\"name\"]]\n",
        "            X_2 = method2embeddings[method_configs[method_j][\"name\"]]\n",
        "            X1TX2 = X_1.T @ X_2\n",
        "            if corr_index in corr_map:\n",
        "                corr_map[corr_index] += X1TX2\n",
        "            else:\n",
        "                corr_map[corr_index] = X1TX2\n",
        "\n",
        "for method_i in range(n_method - 1):\n",
        "    for method_j in range(method_i + 1, n_method):\n",
        "        corr_index = ( method_i, method_j )\n",
        "        trans_index = (method_j, method_i )\n",
        "        corr_map[trans_index] = corr_map[corr_index].T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8mEZ0MYADo5",
        "outputId": "77a8fce0-e23b-4c77-d631-d9711c01cb96"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [03:58<00:00,  9.53s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "pseudo_inverses = {}\n",
        "\n",
        "for i in range(n_method):\n",
        "    # 计算每个方法自身相关性矩阵的伪逆\n",
        "    corr_ii = corr_map[(i, i)].numpy()\n",
        "    pseudo_inv_ii = np.linalg.pinv(corr_ii)\n",
        "\n",
        "    for j in range(n_method):\n",
        "        if i != j:\n",
        "            # 计算交叉相关性矩阵\n",
        "            corr_ij = corr_map[(i, j)].numpy()\n",
        "            # 计算伪逆\n",
        "            pseudo_inverse_ij = pseudo_inv_ii @ corr_ij\n",
        "            pseudo_inverses[(i, j)] = pseudo_inverse_ij\n",
        "\n",
        "# 现在 pseudo_inverses 包含了所有相关性矩阵的伪逆\n"
      ],
      "metadata": {
        "id": "JHvRBS0UFyOK"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "\n",
        "- [ ] 写一下伪逆的存储\n",
        "- [ ] 适当用更多的数据（600条）进行训练后，验证\n",
        "- [ ] 验证能不能放到hf"
      ],
      "metadata": {
        "id": "b1FVcjLdMljz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G4JQXJTKMk8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = {(1,2):3, (2,4):5}"
      ],
      "metadata": {
        "id": "72hd4vOCCdkI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a)"
      ],
      "metadata": {
        "id": "OV2CgZJ6Ch-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eEs-9qbOChSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(method2embeddings[\"openai\"].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4n94fs5SAuVQ",
        "outputId": "01d574a8-af6a-4711-f5e0-9032c234408b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 1536])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VyDA4p_4Bupi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}